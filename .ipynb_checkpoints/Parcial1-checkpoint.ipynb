{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d64cde3d-aff0-47bb-903b-e88eb86a64a1",
   "metadata": {},
   "source": [
    "# Parcial 1 Machine Learning. Binary Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a2f283-bc54-4b55-8e43-db421e429bc8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Funciones y librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "487561bd-eaa7-4115-bd33-d0aabeb3d150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e69b028-23b6-47bb-8d5c-1bbf57262300",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebd0b997-827f-4e95-acdb-e1ba6e0e2ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculo de los IV (Funcion sacada de https://www.kaggle.com/code/puremath86/iv-woe-starter-for-python/notebook)\n",
    "def calc_iv(df, feature, target, pr=False):\n",
    "    lst = []\n",
    "    df[feature] = df[feature].fillna(\"NULL\")\n",
    "\n",
    "    for i in range(df[feature].nunique()):\n",
    "        val = list(df[feature].unique())[i]\n",
    "        lst.append([feature,                                                        # Variable\n",
    "                    val,                                                            # Value\n",
    "                    df[df[feature] == val].count()[feature],                        # All\n",
    "                    df[(df[feature] == val) & (df[target] == 0)].count()[feature],  # Good (think: Fraud == 0)\n",
    "                    df[(df[feature] == val) & (df[target] == 1)].count()[feature]]) # Bad (think: Fraud == 1)\n",
    "\n",
    "    data = pd.DataFrame(lst, columns=['Variable', 'Value', 'All', 'Good', 'Bad'])\n",
    "    data['Share'] = data['All'] / data['All'].sum()\n",
    "    data['Bad Rate'] = data['Bad'] / data['All']\n",
    "    data['Distribution Good'] = (data['All'] - data['Bad']) / (data['All'].sum() - data['Bad'].sum())\n",
    "    data['Distribution Bad'] = data['Bad'] / data['Bad'].sum()\n",
    "    data['WoE'] = np.log(data['Distribution Good'] / data['Distribution Bad'])\n",
    "    \n",
    "    data = data.replace({'WoE': {np.inf: 0, -np.inf: 0}})\n",
    "\n",
    "    data['IV'] = data['WoE'] * (data['Distribution Good'] - data['Distribution Bad'])\n",
    "\n",
    "    data = data.sort_values(by=['Variable', 'Value'], ascending=[True, True])\n",
    "    data.index = range(len(data.index))\n",
    "\n",
    "    if pr:\n",
    "        print(data)\n",
    "        print('IV = ', data['IV'].sum())\n",
    "\n",
    "    iv = data['IV'].sum()\n",
    "    #print('El IV de esta variable es:',iv)\n",
    "    #print(df[feature].value_counts())\n",
    "    return iv, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb859822-b66e-4759-b806-46c4979686e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        \n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Etiqueta')\n",
    "    plt.xlabel('Predicción')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0eca12a-25f7-49da-bb49-77f1d937027e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xtrain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25592/4151200985.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Normalización de los datos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mxtrain_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xtrain' is not defined"
     ]
    }
   ],
   "source": [
    "# Normalización de los datos\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(xtrain)\n",
    "xtrain_scaled = scaler.transform(xtrain)\n",
    "\n",
    "# Una vez normalizados, los datos ahora tienen una media de 0 y una varianza de 1.\n",
    "print(np.round(xtrain_scaled.mean(axis=0),2))\n",
    "print(xtrain_scaled.std(axis=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b9088a-24b5-40f7-9c1c-0f9323aee65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape # Verifico la dimensión de mis datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd54097a-3ff3-4374-8a33-4fe408db2429",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c990e7-662e-4a02-962b-c51b34db3a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se obtienen los datos de los archivos de texto plano\n",
    "xtrain = pd.read_csv(\"datos/xtrain.txt\", sep=\"   \", header=None, engine='python')\n",
    "ytrain = pd.read_csv(\"datos/ytrain.txt\", sep=\"   \", header=None, engine='python')\n",
    "xtest = pd.read_csv(\"datos/xtest.txt\", sep=\"   \", header=None, engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9b5068-6830-403a-b44b-1b22b9de25c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo un dataframe donde agrego la etiqueta de cada dato\n",
    "data_labeled = xtrain\n",
    "data_labeled.columns = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\",  \"N\", \"O\", \"P\"]\n",
    "data_labeled[\"class\"] = ytrain\n",
    "data_labeled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bebf0d-ee1e-4c14-acd2-3d4b8eb01ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de los datos en datos de entramiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(xtrain_scaled, ytrain, test_size=0.3, random_state=31)\n",
    "#X_test, X_predict, y_test, y_predict = train_test_split(X_test, y_test, test_size=0.1, random_state=31)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964e8c41-e8af-4162-8edf-dae2f676881b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Analisis de Descriptores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff877bc1-9fdf-4188-bea3-1d50d45c595c",
   "metadata": {},
   "outputs": [],
   "source": [
    "IVs = {}\n",
    "i = 1\n",
    "for col in data_labeled.columns:\n",
    "    if col != \"class\":\n",
    "        iv, data = calc_iv(xtrain, col, 'class')\n",
    "        IVs[col] = iv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484b03a4-cd4f-47ca-9bf1-a14995f48738",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame([[key, np.round(IVs[key],5)] for key in IVs.keys()], columns=['Feature', 'IV'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343ee353-c277-4e0c-a4b5-2e3a3adb16c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de966dff-592d-410d-9303-bf915fd3ab37",
   "metadata": {},
   "source": [
    "## Selección de Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade4aa0b-0ddc-4fac-b6b3-1757a0107a21",
   "metadata": {},
   "source": [
    "### Regresión Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bed0521-a068-4067-9034-7581a49c6bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=0.8,\n",
    "                           random_state=0,\n",
    "                           solver='lbfgs')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "print(f'Precisión {round(accuracy_score(y_test, y_predict),5)}')\n",
    "print(pd.DataFrame(confusion_matrix(y_test,y_predict)))\n",
    "\n",
    "sns.set_style('white') \n",
    "class_names = ['0','1']\n",
    "plot_confusion_matrix(confusion_matrix(y_test,y_predict),\n",
    "                      classes= class_names, \n",
    "                      title='Matriz de Confusión Normalizada: Regresión Logística')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74feced-5a0b-4153-965d-1f41615252bd",
   "metadata": {},
   "source": [
    "### Redes Neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21c2eef-ac91-4a04-bc40-1b57ff0be016",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier( hidden_layer_sizes=(6, 4), activation='logistic', verbose=True ) # Inicialice un modelo de red neuronal con 2 capas escondidas x 20 neuronas en cada capa y función de activación ReLu #\n",
    "model.fit( X_train, y_train ) # Ajuste el modelo con los datos del conjunto A #\n",
    "y_predict = model.predict( X_test ) # Realice la predicción de etiquetas con los datos de prueba del conjunto A #\n",
    "\n",
    "print(f'Precisión {round(accuracy_score(y_test, y_predict),5)}')\n",
    "print(f'Sensibilidad {round(recall_score(y_test, y_predict),5)}')\n",
    "print(pd.DataFrame(confusion_matrix(y_test,y_predict)))\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix(y_test,y_predict),\n",
    "                      classes=class_names, \n",
    "                      title='Matriz de Confusión Normalizada: Red Neuronal')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcca0946-bb68-452b-aacf-41e59b7020af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434e5a23-6520-477c-b2e2-41a9ee468b91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
